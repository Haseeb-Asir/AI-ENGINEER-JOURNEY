ğŸš€ Day 112 of my AI Engineer Journey

Yesterday, I continued diving deeper into handling missing data (numerical values) â€” and wow, this step really shapes how models behave.

Hereâ€™s what I explored ğŸ‘‡

1ï¸âƒ£ Mean / Median Imputation

When to use:
â†’ Mean if distribution is normal
â†’ Median if distribution is skewed

âœ… Simple, fast, efficient

âŒ Distorts the distribution, can create â€œfakeâ€ outliers, affects covariance

ğŸ” On Titanic dataset â†’ Worked okay for Fare, but badly for Age (distribution got skewed).

2ï¸âƒ£ Arbitrary Value Imputation

Replace missing values with a constant (e.g., -999 or 0).

âœ… Easy to implement, keeps dataset size intact

âŒ Introduces artificial patterns that donâ€™t exist in real-world data

Best used when missingness is not completely at random.

3ï¸âƒ£ End of Distribution Imputation

Assign missing values to extreme ends of the feature distribution.

âœ… Helps models identify â€œmissingnessâ€ as a signal

âŒ Can exaggerate tails and hurt statistical assumptions

ğŸ’¡ Lesson learned:
Not all imputations are equal â€” the distribution of data decides which method makes sense. A fix for one feature might totally break another.

ğŸ‘‰ Data cleaning isnâ€™t glamorous, but itâ€™s where models win or lose.

How do you usually handle missing numerical values â€” mean, median, arbitrary, or something more advanced?

#MachineLearning #DataScience #Python #DataCleaning #LearningInPublic
